type: batch
description: Joining data1 and data2 to calculate
inputs:
  - type: s3
    name: data1
    bucket: datalake
    path: path/{{ds}}/data1.parquet
outputs:
  - type: redshift
    name: batch_table
    schema: dwh
    table: batch_table
  - type: gdrive
    folder: "1jxu_wXJa-r-m0R9JS-gOQpQIzmIoNDdL"
    file_name: report.csv

task_parameters:
    executable: batch.py
    executable_prefix: python
    job_name: papershift
airflow_task_parameters:
template_parameters:
  const: 13
